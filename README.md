# -*- coding: utf-8 -*-
"""Práctica_Agentic_Workflow

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c9eLvu1GzYCh2C0y_EvMStiaGyVNj9cw

# Práctica: Agentic Workflow con modelos LLM

## 1. Caso y objetivo

Los nodos del workflow
Nodo	Función
Recolector de clave de datos	Obtiene y valida información
Verificador de información	Solicitar datos incompletos
Generador de plan estratégico	Generar plan estratégico final

Prompts de agentes
Recolector: examina la conversación y valida: objetivo, plazo, recursos, riesgos y prioridades.
Verificador: pregunta por información faltante, claramente.
Generador: genera plan estratégico en viñetas incluyendo: objetivos, recursos, riesgos y acciones sugeridas priorizadas.


**Caso de uso:** Automatización de generar un plan estratégico en base a información del usuario.

**Objetivo:**  
- Determinar si la información es suficiente  
- Solicitar información incompleta en forma iterativa  
- Generar un plan estratégico en forma estructurada

**Problema:** Generación de planes estratégicos manual, repetitivo, propenso a omisiones.

**Resultado esperado:** plan estratégico en viñetas que incluya:  
- Objetivos  
- Plazos  
- Recursos  
- Riesgos  
- Prioridades  
- Acciones sugeridas
## 2. Diseño de workflow agenticia
**Enfoque:** Esquema basado en agentes especializados que cooperan en función del estado del sistema.

**Flujo global:**  
1. Recolector procesa la conversación y obtiene datos  
2. Verificador pide información incompleta  
3. Generador genera el plan estratégico final

## 3. Estado del agente (AgentState)
Parte 1:

```ts
type AgentState = {
  has_all_details?: boolean;
  initiative_goal?: string;
  target_timeframe?: string;
  current_resources?: string;
  obstacles?: string;
  priorities?: string;
};
4. Nodos del workflow
Nodo	Función
Recolector de datos clave	Extrae y valida información
Verificador de información	Solicita datos faltantes
Generador de plan estratégico	Produce el plan final

5. Prompts de agentes
Recolector: revisa la conversación y valida: objetivo, plazo, recursos, riesgos y prioridades.
Verificador: pregunta solo por la información faltante de manera clara.
Generador: elabora plan en viñetas con objetivos, recursos, riesgos y acciones priorizadas.

6. Diagrama textual del workflow

        [Usuario]
            ↓
[Recolector de datos clave]
      ┌─────────────┐
      │ Info incompleta │ → [Verificador de información] ──┐
      └─────────────┘                                     │
            ↓                                              │
      Info completa                                        │
            ↓                                              │
[Generador de plan estratégico]                             │
            ↓                                              │
       [Resultado final] <─────────────────────────────────┘

## 4. Importaciones y documentación
"""

from __future__ import annotations
# ===========================================================
# PARTE 2: Importaciones y documentación
# ===========================================================
import os
from typing import Any, TypedDict # Import TypedDict
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

from langchain_core.runnables import RunnableLambda

from langgraph.graph import StateGraph, END
import getpass
import json

"""
Automatización agentic tipo recolector-validación-plan.
El agente pregunta, valida, y genera un plan estratégico con LLM.
"""

# Define AgentState as a TypedDict
class AgentState(TypedDict):
    input: str
    has_all_details: bool | None
    initative_goal: str | None
    target_timeframe: str | None
    current_resources: str | None
    obstacles: str | None
    priorities: str | None
    missing_details: str | None
    request_missing: str | None
    plan_estrategico: str | None

# ===========================================================
# PARTE 3: Solicita la clave OPENAI API de forma segura
# ===========================================================
os.environ["OPENAI_API_KEY"] = getpass.getpass("Introduce tu clave de OpenAI API:")

# ===========================================================
# PARTE 4: Definición de nodos del grafo agentic
# ===========================================================

# ------ Nodo: Recolector de datos clave ------
prompt_recolector = ChatPromptTemplate.from_messages([
    ("system",
    """
Revisa si la conversación contiene toda la información:
1. Objetivo clave de la iniciativa
2. Fecha límite o tiempo estimado
3. Recursos disponibles (humanos, presupuesto, herramientas)
4. Obstáculos/Riesgos conocidos
5. Prioridades claves

Responde sólo JSON:
{"has_all_details": true/false, "initative_goal": "...", "target_timeframe": "...", "current_resources": "...", "obstacles": "...", "priorities": "...", "missing_details": "..."}
Si falta algo, ponlo explicamente en 'missing_details' (ejemplo: "Falta prioridad y recursos disponibles").
"""),
    ("human", "{input}")
])
chain_recolector = prompt_recolector | ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

def nodo_recolector(state: AgentState) -> dict[str, Any]: # Return only the updates
    result = chain_recolector.invoke({"input": state["input"]})
    try:
        datos = json.loads(result.content)
    except Exception:
        datos = {"has_all_details": False, "missing_details": "Formato de respuesta no válido"}
    return datos

# ------ Nodo: Verificador ------
prompt_verificador = ChatPromptTemplate.from_messages([
    ("system",
    """
Pregunta al usuario sólo por los datos que han sido detectados como faltantes. Hazlo claro y directo (ej: "¿Puedes indicar cuáles son las prioridades clave y el plazo para la iniciativa?").
"""),
    ("human", "{missing_details}")
])
chain_verificador = prompt_verificador | ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

def nodo_verificador(state: AgentState) -> dict[str, Any]: # Return only the updates
    if state.get("has_all_details"):
        return {}
    pregunta = chain_verificador.invoke({"missing_details": state.get("missing_details", "")})
    return {"request_missing": pregunta.content}

# ------ Nodo: Generador plan estratégico ------
prompt_generador = ChatPromptTemplate.from_messages([
    ("system",
    """
Elabora un plan estratégico en formato viñetas usando la información provista.
Incluye: Objetivo, Plazo, Recursos, Obstáculos, Prioridades si están, Estrategias y una lista de acciones/recomendaciones por prioridad.
Sé formal, claro y estructurado.
"""),
    ("human", "{initative_goal}\n{target_timeframe}\n{current_resources}\n{obstacles}\n{priorities}")
])
chain_generador = prompt_generador | ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

def nodo_generador(state: AgentState) -> dict[str, Any]: # Return only the updates
    res = chain_generador.invoke({
        "initative_goal": state.get("initative_goal", ""),
        "target_timeframe": state.get("target_timeframe", ""),
        "current_resources": state.get("current_resources", ""),
        "obstacles": state.get("obstacles", ""),
        "priorities": state.get("priorities", "")
    })
    return {"plan_estrategico": res.content}

# ===========================================================
# PARTE 5: Definición y compilación del grafo de workflow
# ===========================================================

workflow = StateGraph(AgentState)
workflow.add_node("recolector", nodo_recolector)
workflow.add_node("verificador", nodo_verificador)
workflow.add_node("generador", nodo_generador)
workflow.set_entry_point("recolector")

def check_info_router(state: AgentState) -> str:
    if state.get('has_all_details'): # Use .get for optional fields
        return "generador"
    return "verificador"

# CAMBIADO: Usar add_conditional_edges para workflow dinámico
workflow.add_conditional_edges(
    "recolector",
    check_info_router,
    {
        "generador": "generador",
        "verificador": "verificador",
    },
)

workflow.add_edge("verificador", "recolector")
workflow.add_edge("generador", END)

python_agent = workflow.compile()

# ===========================================================
# PRÁCTICA AGENTIC WORKFLOW - LANGGRAPH
# ===========================================================


# Imports
import json
from typing import TypedDict, Any
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END

# Configuración API
import os
os.environ["OPENAI_API_KEY"] = "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"  # Cambia por tu API Key

# Estado del agente
class AgentState(TypedDict, total=False):
    input: str
    has_all_details: bool
    initiative_goal: str
    target_timeframe: str
    current_resources: str
    obstacles: str
    priorities: str
    missing_details: str
    request_missing: str
    plan_estrategico: str

# Definición del LLM
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# Nodos del workflow

# Nodo recolector de datos
prompt_recolector = ChatPromptTemplate.from_messages([
    ("system",
     """
Revisa si la conversación contiene la información necesaria:
1. Objetivo de la iniciativa
2. Plazo o fecha estimada
3. Recursos disponibles
4. Obstáculos o riesgos
5. Prioridades

Responde SOLO en JSON con esta estructura:
{{"has_all_details": true/false,
  "initiative_goal": "",
  "target_timeframe": "",
  "current_resources": "",
  "obstacles": "",
  "priorities": "",
  "missing_details": ""}}
"""),
    ("human", "{input}")
])

def nodo_recolector(state: AgentState) -> dict[str, Any]:
    response = llm.invoke(prompt_recolector.format_messages(input=state["input"]))
    try:
        return json.loads(response.content)
    except:
        return {"has_all_details": False, "missing_details": "Formato JSON inválido"}

# Nodo verificador de información
prompt_verificador = ChatPromptTemplate.from_messages([
    ("system", "Pregunta claramente SOLO por la información que falta."),
    ("human", "{missing_details}")
])

def nodo_verificador(state: AgentState) -> dict[str, Any]:
    response = llm.invoke(
        prompt_verificador.format_messages(
            missing_details=state.get("missing_details", "")
        )
    )
    return {"request_missing": response.content}

# Nodo generador de plan estratégico
prompt_generador = ChatPromptTemplate.from_messages([
    ("system",
     """
Elabora un plan estratégico claro y estructurado en viñetas.
Incluye objetivo, plazo, recursos, obstáculos, prioridades,
estrategias y acciones por prioridad.
"""),
    ("human",
     "{initiative_goal}\n{target_timeframe}\n{current_resources}\n{obstacles}\n{priorities}")
])

def nodo_generador(state: AgentState) -> dict[str, Any]:
    response = llm.invoke(
        prompt_generador.format_messages(
            initiative_goal=state.get("initiative_goal", ""),
            target_timeframe=state.get("target_timeframe", ""),
            current_resources=state.get("current_resources", ""),
            obstacles=state.get("obstacles", ""),
            priorities=state.get("priorities", "")
        )
    )
    return {"plan_estrategico": response.content}

# Definición del workflow
workflow = StateGraph(AgentState)
workflow.add_node("recolector", nodo_recolector)
workflow.add_node("verificador", nodo_verificador)
workflow.add_node("generador", nodo_generador)

workflow.set_entry_point("recolector")
workflow.add_conditional_edges(
    "recolector",
    lambda state: "generador" if state.get("has_all_details") else "verificador"
)
workflow.add_edge("verificador", END)
workflow.add_edge("generador", END)

python_agent = workflow.compile()

# Ejemplo interactivo
entradas = [
    "Queremos lanzar una campaña para mejorar la comunicación interna.",
    "La prioridad es alta.",
    "El plazo estimado son 3 meses y los recursos serán dos personas con 5000€."
]

estado = {"input": entradas[0]}
print(">>> Usuario:", entradas[0])

for i in range(4):
    result = python_agent.invoke(estado)

    if not result.get("has_all_details", False):
        print("\n[AGENTE] Falta información:")
        print(result.get("request_missing", ""))

        if i + 1 < len(entradas):
            estado["input"] = entradas[i + 1]
            print("\n>>> Usuario:", entradas[i + 1])
        else:
            print("> (No hay más respuestas de usuario, termina aquí.)")
            break
    else:
        print("\n[AGENTE] Plan Estratégico:\n")
        print(result["plan_estrategico"])
        break

"""## 5. Reflexiones y mejoras a considerar

**Reflexión sobre el flujo de trabajo implementado**

1. **Iteración intercativa:**  
   El flujo de trabajo permite preguntar de forma repetida al usuario todo lo necesario para completar todos los datos que hagan falta para generar el plan estratégico real. Asegura que el agente no genere un plan incompleto, pero depende de la paciencia y disponibilidad del usuario.
2. **Sugerencia de extensión:**   
   - Se pueden añadir herramientas externas (por ejemplo, búsquedas en la Web, APIs de bases de datos, validaciones internas…).
   - Integramos el uso de LLMs de diferentes modelos según la complejidad del trabajo a realizar.
   - Implementamos toma de decisiones (auditoría o seguimiento del plan estratégico).
3. **Limitaciones actuales:**  
   - No hay persistencia del historial conversacional por usuario. Para entornos multiusuario o multi-sesión necesitaría guardar estados en bases de datos (ej. MongoDB,PostgreSQL o Redis).
   - La validación de gestión de la entrada de usuario depende completamente de la referencia que hace su LLM de la interpretación.
   - No cuenta con gestión avanzada de errores o reintentos automáticos para errores de conexión o errores de contenido de texto no correcto.
4. **Mejoras como sugerencias:**    
- Guardamos historias de usuario e ir reanudando planes estratégicos, o incluso revisarlos.
- Implementamos validaciones y normalizaciones de dados que se van a introducir una vez pasados al generador de  plan estratégico.

# Diagrama de workflow

La siguiente figura materializa el flujo del agente:

- el flujo del agente empieza en **key data collector**;
- según la evaluación de la condición `has_all_details`, se activa bien el:
  - **Verificador de la información**, caso en el que no hay datos suficientes
  - **Generador de plan estratégico**, caso en el que ya hay datos suficientes;

## 6. Diagrama y codigo de LangGraph
"""

from IPython.display import Image, display

# Mostrar la imagen desde sample_data
display(Image("sample_data/page11.png"))

"""Ejemplo completo del workflow en TypeScript:
import { webSearchTool, Agent, AgentInputItem, Runner, withTrace } from "@openai/agents";
import { z } from "zod";

// ---------------------------
// Definición de herramientas
// ---------------------------
const webSearchPreview = webSearchTool({
  searchContextSize: "medium",
  userLocation: { type: "approximate" }
});

// ---------------------------
// Definición de nodos del agente
// ---------------------------
const RecolectorDeDatosClaveSchema = z.object({
  has_all_details: z.boolean(),
  initative_goal: z.string(),
  target_timeframe: z.string(),
  current_resources: z.string()
});

const recolectorDeDatosClave = new Agent({
  name: "Recolector de datos clave",
  instructions: `
Revisa la conversación y detecta si tenemos toda la información:
1. Objetivo clave de la iniciativa
2. Fecha límite
3. Recursos disponibles
4. Obstáculos y riesgos
5. Prioridades

Si falta información, activa "Verificador de Información".
Si está completa, activa "Generador de Plan Estratégico".
`,
  model: "gpt-5",
  outputType: RecolectorDeDatosClaveSchema,
  modelSettings: { reasoning: { effort: "minimal" }, store: true }
});

const verificadorDeInformaciN = new Agent({
  name: "Verificador de información",
  instructions: `
Pregunta por la información que falta de manera clara y breve.
`,
  model: "gpt-4.1-mini",
  tools: [webSearchPreview],
  modelSettings: { temperature: 1, topP: 1, maxTokens: 2048, store: true }
});

const generadorDePlanEstratGico = new Agent({
  name: "Generador de plan estratégico",
  instructions: `
Crea un plan de acción claro y estructurado, incluyendo objetivos,
plazos, recursos, obstáculos, prioridades, estrategias y acciones
ordenadas por importancia.
`,
  model: "gpt-5",
  modelSettings: { reasoning: { effort: "minimal" }, store: true }
});

// ---------------------------
// Entrada del workflow
// ---------------------------
type WorkflowInput = { input_as_text: string };

// ---------------------------
// Ejecución del workflow
// ---------------------------
export const runWorkflow = async (workflow: WorkflowInput) => {
  return await withTrace("New agent", async () => {
    const state: any = {};
    const conversationHistory: AgentInputItem[] = [
      { role: "user", content: [{ type: "input_text", text: workflow.input_as_text }] }
    ];
    const runner = new Runner({
      traceMetadata: {
        __trace_source__: "agent-builder",
        workflow_id: "wf_695cec435ff4819082f0bf71859136b1038be39894215c2d"
      }
    });
    
    const recolectorResultTemp = await runner.run(recolectorDeDatosClave, [...conversationHistory]);
    conversationHistory.push(...recolectorResultTemp.newItems.map((item) => item.rawItem));

    if (!recolectorResultTemp.finalOutput) throw new Error("Agent result is undefined");

    const recolectorResult = recolectorResultTemp.finalOutput;

    if (recolectorResult.has_all_details) {
      const verificadorResultTemp = await runner.run(verificadorDeInformaciN, [...conversationHistory]);
      conversationHistory.push(...verificadorResultTemp.newItems.map((item) => item.rawItem));
    } else {
      const generadorResultTemp = await runner.run(generadorDePlanEstratGico, [...conversationHistory]);
      conversationHistory.push(...generadorResultTemp.newItems.map((item) => item.rawItem));
    }
  });
};

## 7. Conclusión

El agente del workflow agentic divide situaciones complejas en tareas para ser compartidas entre un conjunto de agentes coordinados utilizando LLM para así tener un generador automatizado de creación estratégica de planes de forma eficaz.
"""
